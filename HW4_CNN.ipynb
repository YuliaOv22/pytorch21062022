{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Практическое задание**"
      ],
      "metadata": {
        "id": "uMPIn2Z0LYe3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Обучите CNN (самописная) на CIFAR-100.\n",
        "2. Обучите CNN на CIFAR-100 через дообучение ImageNet Resnet-50.\n",
        "3. *Обучите CNN на CIFAR-100 через дообучение ImageNet Resnet-50 с аугментацией данных.\n",
        "4. Сравните результаты обучения на эквивалентном числе эпох."
      ],
      "metadata": {
        "id": "_1kh-e0oXz7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from PIL import Image\n",
        "from torchvision import transforms, datasets\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pickle\n",
        "from torchsummary import summary\n",
        "from torchvision import models"
      ],
      "metadata": {
        "id": "OixdPSeBMIWt"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Обучите CNN (самописная) на CIFAR-100.**"
      ],
      "metadata": {
        "id": "QyIm9NKAVUZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# дополнительные классы и функции\n",
        "\n",
        "# класс для загрузки датасета\n",
        "class MyOwnCifar(torch.utils.data.Dataset):\n",
        "   \n",
        "    def __init__(self, init_dataset, transform=None):\n",
        "        self._base_dataset = init_dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._base_dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self._base_dataset[idx][0]\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img, self._base_dataset[idx][1]\n",
        "\n",
        "\n",
        "# функция разделения на train и test\n",
        "def train_valid_split(Xt):\n",
        "    X_train, X_test = train_test_split(Xt, test_size=0.25, random_state=13)\n",
        "    return X_train, X_test"
      ],
      "metadata": {
        "id": "fqXZkK-tuSdH"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# загрузим датасет\n",
        "dataset = datasets.CIFAR100(root='data/', train=True, download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oUPmuoFuEbP",
        "outputId": "c934c890-6b9a-46d2-9d4f-368eab2dae2b"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# укажем параметры для трансформации данных\n",
        "trans_actions = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "# разобьем датасет\n",
        "train_dataset, valid_dataset = train_valid_split(dataset)\n",
        "\n",
        "train_dataset = MyOwnCifar(train_dataset, trans_actions)\n",
        "valid_dataset = MyOwnCifar(valid_dataset, transforms.ToTensor())"
      ],
      "metadata": {
        "id": "OnIVLrzYuEjQ"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128"
      ],
      "metadata": {
        "id": "oNy0nngjz-R6"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# сформируем батчи\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          shuffle=False,\n",
        "                          num_workers=1)"
      ],
      "metadata": {
        "id": "nVq53gyIuElq"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of train batches: {len(train_loader)}')\n",
        "print(f'Number of test batches: {len(valid_loader)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UhMQiuFzts6",
        "outputId": "e59be72b-62fa-4030-f715-7331c637dbb1"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of train batches: 293\n",
            "Number of test batches: 98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# выделим имена классов\n",
        "classes = pickle.load(open('./data/cifar-100-python/meta', 'rb'))\n",
        "classes = classes['fine_label_names']\n",
        "\n",
        "print(classes[:10])\n",
        "print(f'Number of classes: {len(classes)}')"
      ],
      "metadata": {
        "id": "MzR3xip8wtY7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59a3066a-5ebd-4827-efdb-afae10f75cc3"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle']\n",
            "Number of classes: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# посмотрим на изображение в датасете\n",
        "for img, lbl in train_loader:\n",
        "    print(img.shape)\n",
        "    print(classes[lbl[0]])\n",
        "    plt.imshow(img[0].permute(1, 2, 0))\n",
        "    break"
      ],
      "metadata": {
        "id": "nYkC-0f8wtbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "e1f537a8-7f38-4b95-d0b6-e67472d73ea6"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 3, 32, 32])\n",
            "fox\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "iPpe3oSbwteG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "2c0c13df-83aa-4319-ef20-c5b1252c9799"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# создадим архитектуру нейронной сети\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()     \n",
        "                \n",
        "        self.bn1 = torch.nn.BatchNorm2d(3) \n",
        "        self.conv1 = torch.nn.Conv2d(3, 30, 3)\n",
        "\n",
        "        self.bn2 = torch.nn.BatchNorm2d(30) \n",
        "        self.conv2 = torch.nn.Conv2d(30, 60, 3)\n",
        "\n",
        "        self.bn3 = torch.nn.BatchNorm2d(60)\n",
        "\n",
        "        self.fc1 = torch.nn.Linear(960, 200)\n",
        "        self.dp1 = nn.Dropout(0.2)\n",
        "\n",
        "        self.fc2 = torch.nn.Linear(200, 60)\n",
        "        self.dp2 = nn.Dropout(0.2)\n",
        "\n",
        "        self.out = torch.nn.Linear(60, 100)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.bn1(x)\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 3)\n",
        "        \n",
        "        x = self.bn2(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        \n",
        "        x = self.bn3(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dp1(x)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)        \n",
        "        x = self.dp2(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        return self.out(x)\n",
        "\n",
        "\n",
        "net = Net().to(device)\n",
        "print(net)"
      ],
      "metadata": {
        "id": "NUyrKNoduEsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae76a116-24e8-4095-d8fb-f5c8cd33e213"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv1): Conv2d(3, 30, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (bn2): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(30, 60, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (bn3): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc1): Linear(in_features=960, out_features=200, bias=True)\n",
            "  (dp1): Dropout(p=0.2, inplace=False)\n",
            "  (fc2): Linear(in_features=200, out_features=60, bias=True)\n",
            "  (dp2): Dropout(p=0.2, inplace=False)\n",
            "  (out): Linear(in_features=60, out_features=100, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(net.to(device), input_size=(3, 32, 32))"
      ],
      "metadata": {
        "id": "mDaMCtXVuEye",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "211b8b11-2b8a-4f4a-ccce-dd37fc1e7661"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "       BatchNorm2d-1            [-1, 3, 32, 32]               6\n",
            "            Conv2d-2           [-1, 30, 30, 30]             840\n",
            "       BatchNorm2d-3           [-1, 30, 10, 10]              60\n",
            "            Conv2d-4             [-1, 60, 8, 8]          16,260\n",
            "       BatchNorm2d-5             [-1, 60, 4, 4]             120\n",
            "           Dropout-6                  [-1, 960]               0\n",
            "            Linear-7                  [-1, 200]         192,200\n",
            "           Dropout-8                  [-1, 200]               0\n",
            "            Linear-9                   [-1, 60]          12,060\n",
            "           Linear-10                  [-1, 100]           6,100\n",
            "================================================================\n",
            "Total params: 227,646\n",
            "Trainable params: 227,646\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.30\n",
            "Params size (MB): 0.87\n",
            "Estimated Total Size (MB): 1.18\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "cmrAlGha1w9S"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# обучим модель\n",
        "num_epochs = 10\n",
        "net.train()\n",
        "\n",
        "for epoch in range(num_epochs):  \n",
        "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # выводим статистику о процессе обучения\n",
        "        running_loss += loss.item()\n",
        "        running_items += len(labels)\n",
        "        running_right += (labels == torch.max(outputs, 1)[1]).sum()\n",
        "        \n",
        "        # выводим статистику о процессе обучения\n",
        "        if i % 300 == 0:    # печатаем каждые 300 mini-batches\n",
        "            net.eval()\n",
        "            \n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}]. ' \\\n",
        "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "                  f'Loss: {running_loss / running_items:.3f}. ' \\\n",
        "                  f'Acc: {running_right / running_items:.3f}', end='. ')\n",
        "            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "\n",
        "            test_running_right, test_running_total = 0.0, 0.0\n",
        "            for i, data in enumerate(valid_loader):\n",
        "            \n",
        "                test_outputs = net(data[0].to(device))\n",
        "                test_running_total += len(data[1])\n",
        "                test_running_right += (data[1].to(device) == torch.max(test_outputs, 1)[1]).sum()\n",
        "            \n",
        "            print(f'Test acc: {test_running_right / test_running_total:.3f}')\n",
        "       \n",
        "        net.train()\n",
        "        \n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G942K8a31xAg",
        "outputId": "a58e51ef-ba5b-4d2d-9933-b0ab4c616d6c"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10]. Step [1/293]. Loss: 0.036. Acc: 0.023. Test acc: 0.011\n",
            "Epoch [2/10]. Step [1/293]. Loss: 0.030. Acc: 0.086. Test acc: 0.131\n",
            "Epoch [3/10]. Step [1/293]. Loss: 0.027. Acc: 0.148. Test acc: 0.187\n",
            "Epoch [4/10]. Step [1/293]. Loss: 0.025. Acc: 0.203. Test acc: 0.227\n",
            "Epoch [5/10]. Step [1/293]. Loss: 0.021. Acc: 0.328. Test acc: 0.245\n",
            "Epoch [6/10]. Step [1/293]. Loss: 0.023. Acc: 0.266. Test acc: 0.281\n",
            "Epoch [7/10]. Step [1/293]. Loss: 0.020. Acc: 0.305. Test acc: 0.291\n",
            "Epoch [8/10]. Step [1/293]. Loss: 0.021. Acc: 0.281. Test acc: 0.306\n",
            "Epoch [9/10]. Step [1/293]. Loss: 0.020. Acc: 0.352. Test acc: 0.305\n",
            "Epoch [10/10]. Step [1/293]. Loss: 0.021. Acc: 0.305. Test acc: 0.321\n",
            "Training is finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Обучите CNN на CIFAR-100 через дообучение ImageNet Resnet-50.**"
      ],
      "metadata": {
        "id": "7U2FPuQF8-ax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# загрузим предобученную модель\n",
        "resnet50 = models.resnet50(pretrained=True)\n",
        "print(resnet50)"
      ],
      "metadata": {
        "id": "eYrDOCSE1xDP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de369c0a-c80b-4aa2-bed8-a1fb3889ce3d"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# заморозим преобученную модель\n",
        "for param in list(resnet50.parameters())[:]:\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "uOeRYlWm_nKM"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# заменим последний слой на свой, на 100 выходов\n",
        "resnet50.fc = nn.Linear(2048, 100)\n",
        "summary(resnet50.to(device), input_size=(3, 32, 32))"
      ],
      "metadata": {
        "id": "accSOYZu_nNO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f8f13a7-79c0-41d8-8bf8-5d39a89dfe44"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
            "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
            "              ReLU-3           [-1, 64, 16, 16]               0\n",
            "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
            "            Conv2d-5             [-1, 64, 8, 8]           4,096\n",
            "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
            "              ReLU-7             [-1, 64, 8, 8]               0\n",
            "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
            "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
            "             ReLU-10             [-1, 64, 8, 8]               0\n",
            "           Conv2d-11            [-1, 256, 8, 8]          16,384\n",
            "      BatchNorm2d-12            [-1, 256, 8, 8]             512\n",
            "           Conv2d-13            [-1, 256, 8, 8]          16,384\n",
            "      BatchNorm2d-14            [-1, 256, 8, 8]             512\n",
            "             ReLU-15            [-1, 256, 8, 8]               0\n",
            "       Bottleneck-16            [-1, 256, 8, 8]               0\n",
            "           Conv2d-17             [-1, 64, 8, 8]          16,384\n",
            "      BatchNorm2d-18             [-1, 64, 8, 8]             128\n",
            "             ReLU-19             [-1, 64, 8, 8]               0\n",
            "           Conv2d-20             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-21             [-1, 64, 8, 8]             128\n",
            "             ReLU-22             [-1, 64, 8, 8]               0\n",
            "           Conv2d-23            [-1, 256, 8, 8]          16,384\n",
            "      BatchNorm2d-24            [-1, 256, 8, 8]             512\n",
            "             ReLU-25            [-1, 256, 8, 8]               0\n",
            "       Bottleneck-26            [-1, 256, 8, 8]               0\n",
            "           Conv2d-27             [-1, 64, 8, 8]          16,384\n",
            "      BatchNorm2d-28             [-1, 64, 8, 8]             128\n",
            "             ReLU-29             [-1, 64, 8, 8]               0\n",
            "           Conv2d-30             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-31             [-1, 64, 8, 8]             128\n",
            "             ReLU-32             [-1, 64, 8, 8]               0\n",
            "           Conv2d-33            [-1, 256, 8, 8]          16,384\n",
            "      BatchNorm2d-34            [-1, 256, 8, 8]             512\n",
            "             ReLU-35            [-1, 256, 8, 8]               0\n",
            "       Bottleneck-36            [-1, 256, 8, 8]               0\n",
            "           Conv2d-37            [-1, 128, 8, 8]          32,768\n",
            "      BatchNorm2d-38            [-1, 128, 8, 8]             256\n",
            "             ReLU-39            [-1, 128, 8, 8]               0\n",
            "           Conv2d-40            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-41            [-1, 128, 4, 4]             256\n",
            "             ReLU-42            [-1, 128, 4, 4]               0\n",
            "           Conv2d-43            [-1, 512, 4, 4]          65,536\n",
            "      BatchNorm2d-44            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-45            [-1, 512, 4, 4]         131,072\n",
            "      BatchNorm2d-46            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-47            [-1, 512, 4, 4]               0\n",
            "       Bottleneck-48            [-1, 512, 4, 4]               0\n",
            "           Conv2d-49            [-1, 128, 4, 4]          65,536\n",
            "      BatchNorm2d-50            [-1, 128, 4, 4]             256\n",
            "             ReLU-51            [-1, 128, 4, 4]               0\n",
            "           Conv2d-52            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-53            [-1, 128, 4, 4]             256\n",
            "             ReLU-54            [-1, 128, 4, 4]               0\n",
            "           Conv2d-55            [-1, 512, 4, 4]          65,536\n",
            "      BatchNorm2d-56            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-57            [-1, 512, 4, 4]               0\n",
            "       Bottleneck-58            [-1, 512, 4, 4]               0\n",
            "           Conv2d-59            [-1, 128, 4, 4]          65,536\n",
            "      BatchNorm2d-60            [-1, 128, 4, 4]             256\n",
            "             ReLU-61            [-1, 128, 4, 4]               0\n",
            "           Conv2d-62            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-63            [-1, 128, 4, 4]             256\n",
            "             ReLU-64            [-1, 128, 4, 4]               0\n",
            "           Conv2d-65            [-1, 512, 4, 4]          65,536\n",
            "      BatchNorm2d-66            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-67            [-1, 512, 4, 4]               0\n",
            "       Bottleneck-68            [-1, 512, 4, 4]               0\n",
            "           Conv2d-69            [-1, 128, 4, 4]          65,536\n",
            "      BatchNorm2d-70            [-1, 128, 4, 4]             256\n",
            "             ReLU-71            [-1, 128, 4, 4]               0\n",
            "           Conv2d-72            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-73            [-1, 128, 4, 4]             256\n",
            "             ReLU-74            [-1, 128, 4, 4]               0\n",
            "           Conv2d-75            [-1, 512, 4, 4]          65,536\n",
            "      BatchNorm2d-76            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-77            [-1, 512, 4, 4]               0\n",
            "       Bottleneck-78            [-1, 512, 4, 4]               0\n",
            "           Conv2d-79            [-1, 256, 4, 4]         131,072\n",
            "      BatchNorm2d-80            [-1, 256, 4, 4]             512\n",
            "             ReLU-81            [-1, 256, 4, 4]               0\n",
            "           Conv2d-82            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-83            [-1, 256, 2, 2]             512\n",
            "             ReLU-84            [-1, 256, 2, 2]               0\n",
            "           Conv2d-85           [-1, 1024, 2, 2]         262,144\n",
            "      BatchNorm2d-86           [-1, 1024, 2, 2]           2,048\n",
            "           Conv2d-87           [-1, 1024, 2, 2]         524,288\n",
            "      BatchNorm2d-88           [-1, 1024, 2, 2]           2,048\n",
            "             ReLU-89           [-1, 1024, 2, 2]               0\n",
            "       Bottleneck-90           [-1, 1024, 2, 2]               0\n",
            "           Conv2d-91            [-1, 256, 2, 2]         262,144\n",
            "      BatchNorm2d-92            [-1, 256, 2, 2]             512\n",
            "             ReLU-93            [-1, 256, 2, 2]               0\n",
            "           Conv2d-94            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-95            [-1, 256, 2, 2]             512\n",
            "             ReLU-96            [-1, 256, 2, 2]               0\n",
            "           Conv2d-97           [-1, 1024, 2, 2]         262,144\n",
            "      BatchNorm2d-98           [-1, 1024, 2, 2]           2,048\n",
            "             ReLU-99           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-100           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-101            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-102            [-1, 256, 2, 2]             512\n",
            "            ReLU-103            [-1, 256, 2, 2]               0\n",
            "          Conv2d-104            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-105            [-1, 256, 2, 2]             512\n",
            "            ReLU-106            [-1, 256, 2, 2]               0\n",
            "          Conv2d-107           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-108           [-1, 1024, 2, 2]           2,048\n",
            "            ReLU-109           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-110           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-111            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-112            [-1, 256, 2, 2]             512\n",
            "            ReLU-113            [-1, 256, 2, 2]               0\n",
            "          Conv2d-114            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-115            [-1, 256, 2, 2]             512\n",
            "            ReLU-116            [-1, 256, 2, 2]               0\n",
            "          Conv2d-117           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-118           [-1, 1024, 2, 2]           2,048\n",
            "            ReLU-119           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-120           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-121            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-122            [-1, 256, 2, 2]             512\n",
            "            ReLU-123            [-1, 256, 2, 2]               0\n",
            "          Conv2d-124            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-125            [-1, 256, 2, 2]             512\n",
            "            ReLU-126            [-1, 256, 2, 2]               0\n",
            "          Conv2d-127           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-128           [-1, 1024, 2, 2]           2,048\n",
            "            ReLU-129           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-130           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-131            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-132            [-1, 256, 2, 2]             512\n",
            "            ReLU-133            [-1, 256, 2, 2]               0\n",
            "          Conv2d-134            [-1, 256, 2, 2]         589,824\n",
            "     BatchNorm2d-135            [-1, 256, 2, 2]             512\n",
            "            ReLU-136            [-1, 256, 2, 2]               0\n",
            "          Conv2d-137           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-138           [-1, 1024, 2, 2]           2,048\n",
            "            ReLU-139           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-140           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-141            [-1, 512, 2, 2]         524,288\n",
            "     BatchNorm2d-142            [-1, 512, 2, 2]           1,024\n",
            "            ReLU-143            [-1, 512, 2, 2]               0\n",
            "          Conv2d-144            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-145            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-146            [-1, 512, 1, 1]               0\n",
            "          Conv2d-147           [-1, 2048, 1, 1]       1,048,576\n",
            "     BatchNorm2d-148           [-1, 2048, 1, 1]           4,096\n",
            "          Conv2d-149           [-1, 2048, 1, 1]       2,097,152\n",
            "     BatchNorm2d-150           [-1, 2048, 1, 1]           4,096\n",
            "            ReLU-151           [-1, 2048, 1, 1]               0\n",
            "      Bottleneck-152           [-1, 2048, 1, 1]               0\n",
            "          Conv2d-153            [-1, 512, 1, 1]       1,048,576\n",
            "     BatchNorm2d-154            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-155            [-1, 512, 1, 1]               0\n",
            "          Conv2d-156            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-157            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-158            [-1, 512, 1, 1]               0\n",
            "          Conv2d-159           [-1, 2048, 1, 1]       1,048,576\n",
            "     BatchNorm2d-160           [-1, 2048, 1, 1]           4,096\n",
            "            ReLU-161           [-1, 2048, 1, 1]               0\n",
            "      Bottleneck-162           [-1, 2048, 1, 1]               0\n",
            "          Conv2d-163            [-1, 512, 1, 1]       1,048,576\n",
            "     BatchNorm2d-164            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-165            [-1, 512, 1, 1]               0\n",
            "          Conv2d-166            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-167            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-168            [-1, 512, 1, 1]               0\n",
            "          Conv2d-169           [-1, 2048, 1, 1]       1,048,576\n",
            "     BatchNorm2d-170           [-1, 2048, 1, 1]           4,096\n",
            "            ReLU-171           [-1, 2048, 1, 1]               0\n",
            "      Bottleneck-172           [-1, 2048, 1, 1]               0\n",
            "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
            "          Linear-174                  [-1, 100]         204,900\n",
            "================================================================\n",
            "Total params: 23,712,932\n",
            "Trainable params: 204,900\n",
            "Non-trainable params: 23,508,032\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.86\n",
            "Params size (MB): 90.46\n",
            "Estimated Total Size (MB): 96.33\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# переместим модель и данные на целевое устройство\n",
        "resnet50 = resnet50.to(device)"
      ],
      "metadata": {
        "id": "uxe1JfAl_nQD"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# создадим список параметров для адаптации\n",
        "params_to_update = []\n",
        "for name, param in resnet50.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "\n",
        "optimizer = torch.optim.Adam(params_to_update, lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "upwPU-9m_nSz"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# обучим новую модель\n",
        "num_epochs = 10\n",
        "resnet50.train()\n",
        "\n",
        "for epoch in range(num_epochs):  \n",
        "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "    for i, data in enumerate(train_loader):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = resnet50(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # выводим статистику о процессе обучения\n",
        "        running_loss += loss.item()\n",
        "        running_items += len(labels)\n",
        "        running_right += (labels == torch.max(outputs, 1)[1]).sum()\n",
        "        \n",
        "        # выводим статистику о процессе обучения\n",
        "        if i % 300 == 0:    # печатаем каждые 300 mini-batches\n",
        "            resnet50.eval()\n",
        "            \n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}]. ' \\\n",
        "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "                  f'Loss: {running_loss / running_items:.3f}. ' \\\n",
        "                  f'Acc: {running_right / running_items:.3f}', end='. ')\n",
        "            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "\n",
        "            test_running_right, test_running_total = 0.0, 0.0\n",
        "            for i, data in enumerate(valid_loader):\n",
        "            \n",
        "                test_outputs = resnet50(data[0].to(device))\n",
        "                test_running_total += len(data[1])\n",
        "                test_running_right += (data[1].to(device) == torch.max(test_outputs, 1)[1]).sum()\n",
        "            \n",
        "            print(f'Test acc: {test_running_right / test_running_total:.3f}')\n",
        "\n",
        "        resnet50.train()\n",
        "        \n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxEe19aA1xGY",
        "outputId": "ff611983-064d-4230-9348-a0707b67ab9e"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10]. Step [1/293]. Loss: 0.037. Acc: 0.023. Test acc: 0.010\n",
            "Epoch [2/10]. Step [1/293]. Loss: 0.023. Acc: 0.328. Test acc: 0.246\n",
            "Epoch [3/10]. Step [1/293]. Loss: 0.021. Acc: 0.305. Test acc: 0.272\n",
            "Epoch [4/10]. Step [1/293]. Loss: 0.021. Acc: 0.336. Test acc: 0.271\n",
            "Epoch [5/10]. Step [1/293]. Loss: 0.021. Acc: 0.320. Test acc: 0.288\n",
            "Epoch [6/10]. Step [1/293]. Loss: 0.017. Acc: 0.414. Test acc: 0.286\n",
            "Epoch [7/10]. Step [1/293]. Loss: 0.017. Acc: 0.453. Test acc: 0.287\n",
            "Epoch [8/10]. Step [1/293]. Loss: 0.018. Acc: 0.406. Test acc: 0.291\n",
            "Epoch [9/10]. Step [1/293]. Loss: 0.018. Acc: 0.398. Test acc: 0.294\n",
            "Epoch [10/10]. Step [1/293]. Loss: 0.016. Acc: 0.539. Test acc: 0.296\n",
            "Training is finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. *Обучите CNN на CIFAR-100 через дообучение ImageNet Resnet-50 с аугментацией данных.**"
      ],
      "metadata": {
        "id": "ZZh6A9ODHA8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# укажем параметры для трансформации данных\n",
        "train_actions = transforms.Compose([transforms.Resize(64),\n",
        "                                    transforms.RandomCrop(32, padding=2), \n",
        "                                    transforms.ColorJitter(brightness=0.3, contrast=0.2),\n",
        "                                    transforms.RandomVerticalFlip(p=0.1),\n",
        "                                    transforms.ToTensor()])\n",
        "valid_transforms = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "# разобьем датасет\n",
        "train_dataset, valid_dataset = train_valid_split(dataset)\n",
        "\n",
        "train_dataset = MyOwnCifar(train_dataset, train_actions)\n",
        "valid_dataset = MyOwnCifar(valid_dataset, valid_transforms)"
      ],
      "metadata": {
        "id": "DYSBuxMC1xLQ"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# сформируем батчи\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2)\n",
        "\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          shuffle=False,\n",
        "                          num_workers=1)"
      ],
      "metadata": {
        "id": "CnZBy4LBHXtG"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# загрузим предобученную модель\n",
        "resnet50_aug = models.resnet50(pretrained=True)\n",
        "\n",
        "# заморозим преобученную модель\n",
        "for param in list(resnet50_aug.parameters())[:]:\n",
        "    param.requires_grad = False\n",
        "\n",
        "# заменим последний слой на свой, на 100 выходов\n",
        "resnet50_aug.fc = nn.Linear(2048, 100)\n",
        "\n",
        "# переместим модель и данные на целевое устройство\n",
        "resnet50_aug = resnet50_aug.to(device)"
      ],
      "metadata": {
        "id": "viXwGpkJZoil"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# создадим список параметров для адаптации\n",
        "params_to_update = []\n",
        "for name, param in resnet50_aug.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "\n",
        "optimizer = torch.optim.Adam(params_to_update, lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "Bot-l5KWHXwJ"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# обучим новую модель\n",
        "num_epochs = 10\n",
        "resnet50_aug.train()\n",
        "\n",
        "for epoch in range(num_epochs):  \n",
        "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "    for i, data in enumerate(train_loader):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = resnet50_aug(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # выводим статистику о процессе обучения\n",
        "        running_loss += loss.item()\n",
        "        running_items += len(labels)\n",
        "        running_right += (labels == torch.max(outputs, 1)[1]).sum()\n",
        "        \n",
        "        # выводим статистику о процессе обучения\n",
        "        if i % 300 == 0:    # печатаем каждые 300 mini-batches\n",
        "            resnet50_aug.eval()\n",
        "            \n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}]. ' \\\n",
        "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "                  f'Loss: {running_loss / running_items:.3f}. ' \\\n",
        "                  f'Acc: {running_right / running_items:.3f}', end='. ')\n",
        "            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "\n",
        "            test_running_right, test_running_total = 0.0, 0.0\n",
        "            for i, data in enumerate(valid_loader):\n",
        "            \n",
        "                test_outputs = resnet50_aug(data[0].to(device))\n",
        "                test_running_total += len(data[1])\n",
        "                test_running_right += (data[1].to(device) == torch.max(test_outputs, 1)[1]).sum()\n",
        "            \n",
        "            print(f'Test acc: {test_running_right / test_running_total:.3f}')\n",
        "\n",
        "        resnet50_aug.train()\n",
        "        \n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqWl1DwDHXy7",
        "outputId": "57efb1c9-f64e-4833-b938-92a6a1daa744"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10]. Step [1/293]. Loss: 0.037. Acc: 0.008. Test acc: 0.012\n",
            "Epoch [2/10]. Step [1/293]. Loss: 0.029. Acc: 0.141. Test acc: 0.153\n",
            "Epoch [3/10]. Step [1/293]. Loss: 0.027. Acc: 0.227. Test acc: 0.158\n",
            "Epoch [4/10]. Step [1/293]. Loss: 0.028. Acc: 0.125. Test acc: 0.160\n",
            "Epoch [5/10]. Step [1/293]. Loss: 0.026. Acc: 0.227. Test acc: 0.159\n",
            "Epoch [6/10]. Step [1/293]. Loss: 0.027. Acc: 0.227. Test acc: 0.158\n",
            "Epoch [7/10]. Step [1/293]. Loss: 0.027. Acc: 0.172. Test acc: 0.160\n",
            "Epoch [8/10]. Step [1/293]. Loss: 0.028. Acc: 0.211. Test acc: 0.166\n",
            "Epoch [9/10]. Step [1/293]. Loss: 0.029. Acc: 0.188. Test acc: 0.171\n",
            "Epoch [10/10]. Step [1/293]. Loss: 0.027. Acc: 0.258. Test acc: 0.172\n",
            "Training is finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50_aug.eval()\n",
        "for data in valid_loader:\n",
        "  test_outputs = resnet50_aug(data[0].to(device))\n",
        "  label = data[1].to(device) \n",
        "  predict = torch.max(test_outputs, 1)[1]\n",
        "  break\n",
        "print(predict)\n",
        "print(label)\n",
        "print((predict == label).sum()/predict.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5DeImDXSBPt",
        "outputId": "8892b812-0714-4b00-cfe4-08440336aeef"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([74, 42, 61, 85, 89, 78,  8,  8,  2,  0, 59, 39, 87,  8, 41, 78, 49, 72,\n",
            "        64, 64, 76, 48, 98, 18, 45, 14, 89, 14, 50, 79, 64, 94, 69, 49, 14, 78,\n",
            "        61, 48, 82, 51,  8, 22, 78, 22, 53, 79, 82, 88, 42,  8, 93, 78, 49, 37,\n",
            "        54, 39, 78, 12, 59, 78, 85, 85, 41, 42, 53, 10, 86, 41, 42, 86,  6, 48,\n",
            "        48, 49, 48, 41, 78, 54, 78, 14, 53, 20, 22,  6,  6, 13,  6,  7, 26,  8,\n",
            "         8, 78, 49,  8,  6, 74,  2, 68,  2, 42, 39, 17, 50, 36, 53, 86,  8, 72,\n",
            "        82, 75,  8,  8, 10, 49, 59, 14, 82, 88, 61, 29, 24, 14, 78, 89,  8,  8,\n",
            "        78, 41], device='cuda:0')\n",
            "tensor([88, 97,  8, 90, 31, 72, 65, 87, 64,  0,  3, 12, 87, 19, 76, 44, 49, 77,\n",
            "        93, 15, 30, 21, 46, 60, 90, 87, 89, 54, 36, 79, 65, 94, 69, 49, 91, 19,\n",
            "        22, 13, 14, 37, 44, 72, 50, 10, 53, 79, 89, 55, 15, 78,  1, 98, 13, 59,\n",
            "         4, 39,  6, 17, 33, 52, 76, 97, 41, 47, 53, 10, 85, 98, 74, 86, 43, 41,\n",
            "        58, 49, 48, 48, 25, 70, 48, 38, 54, 66, 61, 46, 24, 13, 90,  7, 27, 93,\n",
            "        68, 55, 49, 55, 86, 21, 10, 71, 40, 51, 63, 17, 27, 53, 53, 83, 29, 95,\n",
            "        98, 52, 84, 93, 14, 91, 23, 77, 82, 15, 61,  4, 28, 92, 19,  5, 64, 79,\n",
            "        38, 41], device='cuda:0')\n",
            "tensor(0.1953, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N = 20\n",
        "plt.imshow(data[0][N,:,:,:].permute(1, 2, 0)/data[0][N,:,:,:].max())\n",
        "plt.title(classes[label[N]]+'_'+classes[predict[N]])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "n4oa_FHLSGYL",
        "outputId": "4fb88001-39f7-4d5f-92ad-fbf0f70baf92"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Сравните результаты обучения на эквивалентном числе эпох.**"
      ],
      "metadata": {
        "id": "xQdDuQVuRjby"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим на результаты работы трех моделей на 10 эпохах:\n",
        "\n",
        "**1. Самописная нейронная сеть:**\n",
        "\n",
        "Epoch [10/10]. Step [1/293]. Loss: 0.021. Acc: 0.305. **Test acc: 0.321**\n",
        "\n",
        "**2. Resnet50:**\n",
        "\n",
        "Epoch [10/10]. Step [1/293]. Loss: 0.016. Acc: 0.539. **Test acc: 0.296**\n",
        "\n",
        "**3. Resnet50 с аугментацией данных:**\n",
        "\n",
        "Epoch [10/10]. Step [1/293]. Loss: 0.027. Acc: 0.258. **Test acc: 0.172**\n",
        "\n",
        "Наилучший результат на тестовых данных показала самописная модель. По метрике модели Resnet50 видно, что она начала переобучаться, на тесте точность росла медленно и разница между трейном и тестом становилась все больше. В архитетуре самой нейронной сети нет, к примеру, даже слоев Dropout, поэтому такое поведение вполне возможно. У третьей модели с аугментацией данных сильного переобучения не происходит, но и результат по метрике получается хуже. Вероятно, модели требуется больше эпох для обучения. "
      ],
      "metadata": {
        "id": "Mb7EhMW8RmHs"
      }
    }
  ]
}